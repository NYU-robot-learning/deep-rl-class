---
id: lectures
title: Course Schedule
---
 
| wk | Lecture | Slides | Reading material |
|---|---|---|---|
| 9/1 | HW-0 Release | | Fundamentals of Linear Algebra and Deep Learning|
| 9/3 | Part 1: Course overview <br />Part 2: Supervised learning for control | | <br />1\. [A framework for behavioural cloning, Bain and Sommut, 1999.](http://www.cse.unsw.edu.au/~claude/papers/MI15.pdf)<br />2\. [A reduction of imitation learning and structured prediction to no-regret online learning, Ross et al., 2011.](http://proceedings.mlr.press/v15/ross11a/ross11a.pdf) |
| 9/10 | Part 1: Introduction to RL<br />Part 2: Value functions | |Part 1: Chapter 1 of [RL book](http://incompleteideas.net/book/RLbook2020.pdf).<br />Part 2: Chapter 3 of [RL book](http://incompleteideas.net/book/RLbook2020.pdf). |
| 9/10 | HW-0 Due | | |
| 9/10 | HW-1 Release | | Imitation via Supervision.|
| 9/17 | Deep Q Learning | |1\. [Human-level control through deep reinforcement learning, Mnih et al., 2015](https://daiwk.github.io/assets/dqn.pdf).<br />2\. [Rainbow: Combining Improvements in Deep Reinforcement Learning, Hessel et al., 2017.](https://arxiv.org/pdf/1710.02298.pdf)Â <br /> 3\. [Agent 57, Deepmind blog post](https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark) |
| 9/17 | HW-1 Due | | |
| 9/17 | HW-2 Release | | Deep Q Learning++.|
| 9/24 | Policy gradients | |1\. [REINFORCE, Williams, 1992.](https://link.springer.com/content/pdf/10.1007/BF00992696.pdf)<br />2\. [A Natural Policy Gradient, Kakade, 2002](https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf).<br />3\. [Proximal Policy Optimization Algorithms, Schulman et al. 2017.](https://arxiv.org/pdf/1707.06347.pdf) |
| 10/1 | Part 1: Actor-critic methods<br />Part 2: Distributed RL | | 1\. [Deterministic Policy Gradient Algorithms, Silver et al., 2014.](http://proceedings.mlr.press/v32/silver14.pdf)<br />2\. [Asynchronous Methods for Deep Reinforcement Learning, Mnih et al. 2016.](https://arxiv.org/pdf/1602.01783.pdf)<br />3\. [Massively Parallel Methods for Deep Reinforcement Learning, Nair et al. 2015.](https://arxiv.org/pdf/1507.04296.pdf) |
| 10/1 | HW-2 Due | | |
| 10/1 | HW-3 Release | | RL with Policy Gradients.|
| 10/8  | Exploration in RL  |  | 1\. [Exploration strategies in deep RL, blog by Lilian Weng, 2020](https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html) <br /> 2\. [Intrinsic Motivation Systems for Autonomous Mental Development, Oudeyer et al. 2007.](http://www.pyoudeyer.com/ims.pdf) <br /> 3\. [Curiosity-driven Exploration by Self-supervised Prediction, Pathak et al. 2017.](https://arxiv.org/pdf/1705.05363.pdf)  |
| 10/9 | Project Proposals Due | | |
| 10/15  | Generalization in RL  |  | 1\. [Quantifying Generalization in RL, blog by OpenAI 2018](https://openai.com/blog/quantifying-generalization-in-reinforcement-learning)<br /> 2\. [Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700 Robot Hours, Pinto and Gupta 2016](https://arxiv.org/pdf/1509.06825.pdf) <br />3\. [Visual Imitation Made Easy, Young et al. 2020](https://arxiv.org/pdf/2008.04899.pdf)  |
| 10/15 | HW-3 Due | | |
| 10/15 | HW-4 Release | | Exploration with Bandits.|
| 10/22  | Imitation Learning  |  | 1\. [Apprenticeship Learning via Inverse Reinforcement Learning, Abbeel and Ng 2004](https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf) <br />2\. [Generative Adversarial Imitation Learning, Ho et al. 2016](https://arxiv.org/pdf/1606.03476.pdf) <br />3\. [Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations, Rajeswaran et al. 2018](https://arxiv.org/pdf/1709.10087.pdf)  |
| 10/22 | HW-4 Due | | |
| 10/22 | HW-5 Release | | Adaptive Control and Optimization.|
| 10/29  | Control and planning  |  | 1\. [Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems, Li and Todorov 2004](https://homes.cs.washington.edu/~todorov/papers/LiICINCO04.pdf) <br />2\. [Benchmarking Model-Based Reinforcement Learning, Wang et al. 2019](https://arxiv.org/pdf/1907.02057.pdf)  |
| 10/29 | HW-5 Due | | |
| 10/29 | HW-6 Release | | Learning General Policies.|
| 11/5  | Part 1: Meta learning Part 2: Offline RL  |  | Guest Lecture |
| 11/12  | RL for Robotics  |  |  |
| 11/12  | HW-6 Due | | |
| 11/19  | Part 1: RL for protein folding Part 2: RL for circuit design  |  | Guest Lecture |
| 12/3  | Current frontiers  |  |  |
| 12/10  | Final Project Presentations and Writeups |  |  |

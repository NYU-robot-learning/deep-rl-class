<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.1">
<title data-react-helmet="true">Course Schedule | Deep Reinforcement Learning</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://nyu-robot-learning.github.io//deep-rl-class/docs/lectures"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Course Schedule | Deep Reinforcement Learning"><meta data-react-helmet="true" name="description" content="| wk | Lecture | Slides | Reading material |"><meta data-react-helmet="true" property="og:description" content="| wk | Lecture | Slides | Reading material |"><meta data-react-helmet="true" property="og:image" content="https://nyu-robot-learning.github.io//deep-rl-class/img/logo-og.png"><meta data-react-helmet="true" name="twitter:image" content="https://nyu-robot-learning.github.io//deep-rl-class/img/logo-og.png"><link data-react-helmet="true" rel="shortcut icon" href="/deep-rl-class/img/favicon/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://nyu-robot-learning.github.io//deep-rl-class/docs/lectures"><link data-react-helmet="true" rel="alternate" href="https://nyu-robot-learning.github.io//deep-rl-class/docs/lectures" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://nyu-robot-learning.github.io//deep-rl-class/docs/lectures" hreflang="x-default"><link rel="stylesheet" href="/deep-rl-class/assets/css/styles.c519d9dd.css">
<link rel="preload" href="/deep-rl-class/assets/js/runtime~main.c107efbe.js" as="script">
<link rel="preload" href="/deep-rl-class/assets/js/main.2b1aa267.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#main" class="skipToContent_1oUP shadow--md">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/deep-rl-class/"><b class="navbar__title">Deep Reinforcement Learning</b></a><a class="navbar__item navbar__link" href="/deep-rl-class/docs/logistics">Logistics</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/deep-rl-class/docs/lectures">Schedule</a><a class="navbar__item navbar__link" href="/deep-rl-class/docs/assignments">Assignments</a></div><div class="navbar__items navbar__items--right"><div class="react-toggle displayOnlyInLargeViewport_GrZ2 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/deep-rl-class/"><b class="navbar__title">Deep Reinforcement Learning</b></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/deep-rl-class/docs/logistics">Logistics</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/deep-rl-class/docs/lectures">Schedule</a></li><li class="menu__list-item"><a class="menu__link" href="/deep-rl-class/docs/assignments">Assignments</a></li></ul></div></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_31aa"><main class="docMainContainer_3ufF docMainContainerEnhanced_3NYZ"><div class="container padding-top--md padding-bottom--lg docItemWrapper_3FMP"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="markdown"><header><h1 class="h1Heading_27L5">Course Schedule</h1></header><table><thead><tr><th>wk</th><th>Lecture</th><th>Slides</th><th>Reading material</th></tr></thead><tbody><tr><td>9/1</td><td>HW-0 Release</td><td></td><td>Fundamentals of Linear Algebra and Deep Learning</td></tr><tr><td>9/3</td><td>Part 1: Course overview <br>Part 2: Supervised learning for control</td><td></td><td><br>1. <a href="http://www.cse.unsw.edu.au/~claude/papers/MI15.pdf" target="_blank" rel="noopener noreferrer">A framework for behavioural cloning, Bain and Sommut, 1999.</a><br>2. <a href="http://proceedings.mlr.press/v15/ross11a/ross11a.pdf" target="_blank" rel="noopener noreferrer">A reduction of imitation learning and structured prediction to no-regret online learning, Ross et al., 2011.</a></td></tr><tr><td>9/10</td><td>Part 1: Introduction to RL<br>Part 2: Value functions</td><td></td><td>Part 1: Chapter 1 of <a href="http://incompleteideas.net/book/RLbook2020.pdf" target="_blank" rel="noopener noreferrer">RL book</a>.<br>Part 2: Chapter 3 of <a href="http://incompleteideas.net/book/RLbook2020.pdf" target="_blank" rel="noopener noreferrer">RL book</a>.</td></tr><tr><td>9/10</td><td>HW-0 Due</td><td></td><td></td></tr><tr><td>9/10</td><td>HW-1 Release</td><td></td><td>Imitation via Supervision.</td></tr><tr><td>9/17</td><td>Deep Q Learning</td><td></td><td>1. <a href="https://daiwk.github.io/assets/dqn.pdf" target="_blank" rel="noopener noreferrer">Human-level control through deep reinforcement learning, Mnih et al., 2015</a>.<br>2. <a href="https://arxiv.org/pdf/1710.02298.pdf" target="_blank" rel="noopener noreferrer">Rainbow: Combining Improvements in Deep Reinforcement Learning, Hessel et al., 2017.</a>Â <br> 3. <a href="https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark" target="_blank" rel="noopener noreferrer">Agent 57, Deepmind blog post</a></td></tr><tr><td>9/17</td><td>HW-1 Due</td><td></td><td></td></tr><tr><td>9/17</td><td>HW-2 Release</td><td></td><td>Deep Q Learning++.</td></tr><tr><td>9/24</td><td>Policy gradients</td><td></td><td>1. <a href="https://link.springer.com/content/pdf/10.1007/BF00992696.pdf" target="_blank" rel="noopener noreferrer">REINFORCE, Williams, 1992.</a><br>2. <a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" target="_blank" rel="noopener noreferrer">A Natural Policy Gradient, Kakade, 2002</a>.<br>3. <a href="https://arxiv.org/pdf/1707.06347.pdf" target="_blank" rel="noopener noreferrer">Proximal Policy Optimization Algorithms, Schulman et al. 2017.</a></td></tr><tr><td>10/1</td><td>Part 1: Actor-critic methods<br>Part 2: Distributed RL</td><td></td><td>1. <a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener noreferrer">Deterministic Policy Gradient Algorithms, Silver et al., 2014.</a><br>2. <a href="https://arxiv.org/pdf/1602.01783.pdf" target="_blank" rel="noopener noreferrer">Asynchronous Methods for Deep Reinforcement Learning, Mnih et al. 2016.</a><br>3. <a href="https://arxiv.org/pdf/1507.04296.pdf" target="_blank" rel="noopener noreferrer">Massively Parallel Methods for Deep Reinforcement Learning, Nair et al. 2015.</a></td></tr><tr><td>10/1</td><td>HW-2 Due</td><td></td><td></td></tr><tr><td>10/1</td><td>HW-3 Release</td><td></td><td>RL with Policy Gradients.</td></tr><tr><td>10/8</td><td>Exploration in RL</td><td></td><td>1. <a href="https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html" target="_blank" rel="noopener noreferrer">Exploration strategies in deep RL, blog by Lilian Weng, 2020</a> <br> 2. <a href="http://www.pyoudeyer.com/ims.pdf" target="_blank" rel="noopener noreferrer">Intrinsic Motivation Systems for Autonomous Mental Development, Oudeyer et al. 2007.</a> <br> 3. <a href="https://arxiv.org/pdf/1705.05363.pdf" target="_blank" rel="noopener noreferrer">Curiosity-driven Exploration by Self-supervised Prediction, Pathak et al. 2017.</a></td></tr><tr><td>10/9</td><td>Project Proposals Due</td><td></td><td></td></tr><tr><td>10/15</td><td>Generalization in RL</td><td></td><td>1. <a href="https://openai.com/blog/quantifying-generalization-in-reinforcement-learning" target="_blank" rel="noopener noreferrer">Quantifying Generalization in RL, blog by OpenAI 2018</a><br> 2. <a href="https://arxiv.org/pdf/1509.06825.pdf" target="_blank" rel="noopener noreferrer">Supersizing Self-supervision: Learning to Grasp from 50K Tries and 700 Robot Hours, Pinto and Gupta 2016</a> <br>3. <a href="https://arxiv.org/pdf/2008.04899.pdf" target="_blank" rel="noopener noreferrer">Visual Imitation Made Easy, Young et al. 2020</a></td></tr><tr><td>10/15</td><td>HW-3 Due</td><td></td><td></td></tr><tr><td>10/15</td><td>HW-4 Release</td><td></td><td>Exploration with Bandits.</td></tr><tr><td>10/22</td><td>Imitation Learning</td><td></td><td>1. <a href="https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf" target="_blank" rel="noopener noreferrer">Apprenticeship Learning via Inverse Reinforcement Learning, Abbeel and Ng 2004</a> <br>2. <a href="https://arxiv.org/pdf/1606.03476.pdf" target="_blank" rel="noopener noreferrer">Generative Adversarial Imitation Learning, Ho et al. 2016</a> <br>3. <a href="https://arxiv.org/pdf/1709.10087.pdf" target="_blank" rel="noopener noreferrer">Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations, Rajeswaran et al. 2018</a></td></tr><tr><td>10/22</td><td>HW-4 Due</td><td></td><td></td></tr><tr><td>10/22</td><td>HW-5 Release</td><td></td><td>Adaptive Control and Optimization.</td></tr><tr><td>10/29</td><td>Control and planning</td><td></td><td>1. <a href="https://homes.cs.washington.edu/~todorov/papers/LiICINCO04.pdf" target="_blank" rel="noopener noreferrer">Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems, Li and Todorov 2004</a> <br>2. <a href="https://arxiv.org/pdf/1907.02057.pdf" target="_blank" rel="noopener noreferrer">Benchmarking Model-Based Reinforcement Learning, Wang et al. 2019</a></td></tr><tr><td>10/29</td><td>HW-5 Due</td><td></td><td></td></tr><tr><td>10/29</td><td>HW-6 Release</td><td></td><td>Learning General Policies.</td></tr><tr><td>11/5</td><td>Part 1: Meta learning Part 2: Offline RL</td><td></td><td>Guest Lecture</td></tr><tr><td>11/12</td><td>RL for Robotics</td><td></td><td></td></tr><tr><td>11/12</td><td>HW-6 Due</td><td></td><td></td></tr><tr><td>11/19</td><td>Part 1: RL for protein folding Part 2: RL for circuit design</td><td></td><td>Guest Lecture</td></tr><tr><td>12/3</td><td>Current frontiers</td><td></td><td></td></tr><tr><td>12/10</td><td>Final Project Presentations and Writeups</td><td></td><td></td></tr></tbody></table></div><footer class="row docusaurus-mt-lg"><div class="col"></div><div class="col lastUpdated_3DPF">Last updated on <b><time datetime="2021-06-23T21:51:25.000Z">6/23/2021</time></b></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Resources</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/deep-rl-class/docs/lectures">Schedule</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://campuswire.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Class Campuswire</a></li><li class="footer__item"><a class="footer__link-item" href="/deep-rl-class/docs/logistics#course-staff">Staff information</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2021 NYU Generalizable Robotics and AI Lab</div></div></div></footer></div>
<script src="/deep-rl-class/assets/js/runtime~main.c107efbe.js"></script>
<script src="/deep-rl-class/assets/js/main.2b1aa267.js"></script>
</body>
</html>